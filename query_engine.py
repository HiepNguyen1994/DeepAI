import os, json, faiss, numpy as np, openai, re
from datetime import datetime
import os, json, faiss, numpy as np, openai, re
from datetime import datetime
from rank_bm25 import BM25Okapi
from collections import defaultdict

openai.api_key = "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"

# query_engine.py - ƒê√£ fix fallback BM25 + FAISS + l·ªçc th·ªùi gian


# ==== C·∫§U H√åNH ====
BASE_FOLDER = os.getcwd()
FAISS_INDEX_PATH = os.path.join(BASE_FOLDER, "faiss_banking_index.bin")
KEY_MAP_PATH = os.path.join(BASE_FOLDER, "faiss_key_map.json")
EMBEDDING_DIM = 3072  # openai text-embedding-3-large

# ==== LOAD DATA ====
index = faiss.read_index(FAISS_INDEX_PATH)

with open(KEY_MAP_PATH, "r", encoding="utf-8") as f:
    key_map = json.load(f)

def extract_date_from_filename(file_name):
    if not file_name:
        return None
    try:
        clean = file_name.strip().lower().replace("_", "").replace(" ", "")

        # Tr∆∞·ªùng h·ª£p: YYYYMMDD
        match = re.search(r'(\d{8})', clean)
        if match:
            return datetime.strptime(match.group(1), "%Y%m%d")

        # Tr∆∞·ªùng h·ª£p: Q1-2024 ho·∫∑c Q12024
        match = re.search(r'q([1-4])[-/]?(\d{4})', clean)
        if match:
            q, y = int(match.group(1)), int(match.group(2))
            return datetime(y, (q - 1) * 3 + 1, 1)

        # Tr∆∞·ªùng h·ª£p ch·ªâ c√≥ nƒÉm YYYY
        match = re.search(r'(\d{4})', clean)
        if match:
            return datetime(int(match.group(1)), 1, 1)

    except Exception as e:
        print(f"[‚ùå EXTRACT ERROR] {file_name} ‚Üí {e}")
    
    return None  # r√µ r√†ng return None n·∫øu kh√¥ng match g√¨ c·∫£

def filter_by_time(results, time_filter):
    if not time_filter or time_filter.lower() == "t·∫•t c·∫£":
        return results

    # L·ªçc m·ªõi nh·∫•t theo ng√†y c√≥ th·ªÉ x√°c ƒë·ªãnh ƒë∆∞·ª£c
    if time_filter.lower() == "m·ªõi nh·∫•t":
        dated_results = [r for r in results if extract_date_from_filename(r["file_name"])]
        dated_results.sort(key=lambda x: extract_date_from_filename(x["file_name"]), reverse=True)
        return dated_results[:1] if dated_results else results[:20]

    # L·ªçc theo qu√Ω (Q1-2024...)
    match = re.search(r'Q([1-4])[/-](\d{4})', time_filter)
    if match:
        q, y = int(match[1]), int(match[2])
        start = datetime(y, (q - 1) * 3 + 1, 1)
        end = datetime(y, (q - 1) * 3 + 3, 28)
        filtered = [
            r for r in results 
            if (d := extract_date_from_filename(r["file_name"])) and start <= d <= end
        ]
        print(f"[DEBUG] üéØ L·ªçc theo qu√Ω {time_filter} c√≤n {len(filtered)} ƒëo·∫°n")
        return filtered

    # L·ªçc theo nƒÉm
    match = re.search(r'(\d{4})', time_filter)
    if match:
        y = int(match[1])
        filtered = [
            r for r in results 
            if (d := extract_date_from_filename(r["file_name"])) and d.year == y
        ]
        print(f"[DEBUG] üéØ L·ªçc theo nƒÉm {y} c√≤n {len(filtered)} ƒëo·∫°n")
        return filtered

    # L·ªçc theo ng√†y c·ª• th·ªÉ YYYY-MM-DD
    try:
        target = datetime.strptime(time_filter, "%Y-%m-%d")
        filtered = [
            r for r in results 
            if extract_date_from_filename(r["file_name"]) == target
        ]
        print(f"[DEBUG] üéØ L·ªçc theo ng√†y {target.strftime('%Y-%m-%d')} c√≤n {len(filtered)} ƒëo·∫°n")
        return filtered
    except:
        print("[DEBUG] ‚ö†Ô∏è Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c th·ªùi gian, gi·ªØ nguy√™n to√†n b·ªô")
        return results


def get_bm25_indices(doc_name, sources, top_n=2000):
    contents = []
    valid_indices = []

    for i, item in enumerate(key_map):
        file_name = item["file_name"].lower()
        source_match = (
            "t·∫•t c·∫£" in sources
            or any(src.lower() in file_name for src in sources)
        )

        if source_match:
            contents.append((item["content"] + " " + file_name).lower())
            valid_indices.append(i)

    if not contents:
        print("[WARN] ‚ùó BM25 kh√¥ng t√¨m ƒë∆∞·ª£c ƒëo·∫°n ph√π h·ª£p.")
        return []

    tokenized = [c.split() for c in contents]
    bm25 = BM25Okapi(tokenized)
    scores = bm25.get_scores(doc_name.lower().split())
    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]
    return [valid_indices[i] for i in top_indices]



def search_faiss(query, valid_indices, k=800):
    query_vec = openai.embeddings.create(model="text-embedding-3-large", input=[query]).data[0].embedding
    query_vec = np.array(query_vec, dtype=np.float32).reshape(1, -1)
    D, I = index.search(query_vec, k)

    valid_set = set(valid_indices)
    return [key_map[idx] for idx in I[0] if idx in valid_set and idx < len(key_map)]

def smart_filter_faiss(faiss_results, doc_name, time_filter, sources):
    def match(item, doc=None, year=None, srcs=None):
        full_text = (item["file_name"] + " " + item["content"]).lower()
        doc_ok = doc.lower() in full_text if doc else True
        year_ok = year in full_text if year else True
        src_ok = any(src.lower() in full_text for src in srcs) if srcs else True
        return doc_ok and year_ok and src_ok

    match_year = re.search(r'Q[1-4][/-](\d{4})', time_filter) or re.search(r'(\d{4})', time_filter)
    year = match_year.group(1) if match_year else None
    srcs = [s for s in sources if s.lower() != "t·∫•t c·∫£"]

    # Gom t·ª´ng t·∫ßng ‚Üí tr√°nh m·∫•t HSC khi VDSC tr√∫ng tr∆∞·ªõc
    results = []
    seen_files = set()

    filter_levels = [
        ("üéØ VPB + nƒÉm + ngu·ªìn", dict(doc=doc_name, year=year, srcs=srcs)),
        ("üîÑ VPB + nƒÉm", dict(doc=doc_name, year=year, srcs=None)),
        ("üîÑ VPB + ngu·ªìn", dict(doc=doc_name, year=None, srcs=srcs)),
        ("üîÑ Ngu·ªìn + nƒÉm", dict(doc=None, year=year, srcs=srcs)),  # <-- t·∫ßng th√™m v√†o
        ("üîÑ Ch·ªâ VPB", dict(doc=doc_name, year=None, srcs=None)),
    ]

    for label, cond in filter_levels:
        batch = [
            r for r in faiss_results
            if match(r, **cond) and r["file_name"] not in seen_files
        ]
        if batch:
            print(f"[DEBUG] {label} ‚Üí {len(batch)} ƒëo·∫°n")
            results.extend(batch)
            seen_files.update(r["file_name"] for r in batch)

    return results


# === GPT SYSTEM PROMPT ===
SYSTEM_PROMPT = """
B·∫°n l√† chuy√™n vi√™n ph√¢n t√≠ch cao c·∫•p ng√†nh ng√¢n h√†ng.

Y√™u c·∫ßu:
- Ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi c√°c con s·ªë ho·∫∑c t·ª∑ l·ªá n·∫øu ch√∫ng **xu·∫•t hi·ªán nguy√™n vƒÉn trong t√†i li·ªáu truy xu·∫•t ƒë∆∞·ª£c t·ª´ FAISS**. 
N·∫øu kh√¥ng c√≥ s·ªë c·ª• th·ªÉ, h√£y n√≥i r·∫±ng: "Kh√¥ng th·∫•y con s·ªë c·ª• th·ªÉ trong t√†i li·ªáu".
Tuy·ªát ƒë·ªëi kh√¥ng ph·ªèng ƒëo√°n ho·∫∑c ∆∞·ªõc l∆∞·ª£ng.
- Gi·ªçng vƒÉn x√©o x·∫Øt, th√¥ng minh, c·ª±c k·ª≥ logic, ƒë·ª´ng ƒë·ªÉ sai ch√≠nh t·∫£ v√† kh√¥ng b·ªãa n·ªôi dung. 
- Tr√≠ch xu·∫•t c√°c lu·∫≠n ƒëi·ªÉm r√µ r√†ng, c√≥ d·∫´n ch·ª©ng v√† s·ªë li·ªáu c·ª• th·ªÉ.
- Vi·∫øt phong c√°ch ph√¢n t√≠ch t√†i ch√≠nh kh√°ch quan, m·∫°ch l·∫°c.
- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß, tr√¨nh b√†y trung th·ª±c thay v√¨ suy ƒëo√°n.
- N·∫øu c√≥ th·ªÉ, h√£y ghi r√µ t√™n t·ªï ch·ª©c ph√°t h√†nh t√†i li·ªáu (v√≠ d·ª•: VDSC, BSC...).
"""

# === MAIN ===
def get_answer(doc_name: str, time_filter: str, sources: list, user_prompt: str):
    print("[INFO] üîé ƒêang l·ªçc BM25...")
    filtered_indices = get_bm25_indices(doc_name, sources)
    print(f"[DEBUG] BM25 l·∫•y {len(filtered_indices)} ƒëo·∫°n")

    query_text = f"{doc_name}. {user_prompt}"
    faiss_results = search_faiss(query_text, filtered_indices)
    print(f"[DEBUG] FAISS tr·∫£ v·ªÅ {len(faiss_results)} ƒëo·∫°n")

    filtered_results = smart_filter_faiss(faiss_results, doc_name, time_filter, sources)

    if not filtered_results:
        print("[WARN] ‚ùó smart_filter_faiss kh√¥ng c√≥ k·∫øt qu·∫£, fallback faiss_results")
        filtered_results = faiss_results[:10]

    # K·∫øt h·ª£p c·∫£ 2: ƒë·∫£m b·∫£o m·ªói ngu·ªìn xu·∫•t hi·ªán √≠t nh·∫•t 2 ƒëo·∫°n (n·∫øu c√≥)
    filtered_results_by_source = []
    seen_files = set()


    for source in sources:
        source_filtered = [
            item for item in filtered_results
            if source.lower() in item['file_name'].lower() and item['file_name'] not in seen_files
        ]
        if source_filtered:
            selected = source_filtered[:15]  # l·∫•y t·ªëi ƒëa 15 ƒëo·∫°n t·ª´ m·ªói ngu·ªìn
            filtered_results_by_source.extend(selected)
            seen_files.update(item['file_name'] for item in selected)

    # N·∫øu kh√¥ng ƒë·ªß 5 ƒëo·∫°n, l·∫•y th√™m ƒë·ªÉ ƒë·ªß context
    if len(filtered_results_by_source) < 5:
        additional_results = [item for item in filtered_results if item['file_name'] not in seen_files]
        filtered_results_by_source.extend(additional_results[:5 - len(filtered_results_by_source)])

    context = "\n\n".join(
        f"Ngu·ªìn: [{next((src for src in sources if src.lower() in item['file_name'].lower()), 'Kh√¥ng r√µ')}] - {item['file_name']}\n"
        f"N·ªôi dung: {item['content']}"
        for item in filtered_results_by_source
    )

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT.strip()},
            {"role": "user", "content": f"""üìñ **D·ªØ li·ªáu FAISS:**\n\n{context}\n\nüìå **Y√™u c·∫ßu:**\n{user_prompt}"""}
        ],
        max_tokens=3000,
    )

    return response.choices[0].message.content







#
#
# def get_answer(doc_name: str, time_filter: str, user_prompt: str):
#     filtered_indices = get_bm25_indices(doc_name)
#     print("[DEBUG] BM25 filtered:", len(filtered_indices))
#
#     query_text = f"{doc_name}. {user_prompt}"
#     faiss_results = search_faiss(query_text, filtered_indices, k=70)
#     print("[DEBUG] FAISS raw:", len(faiss_results))
#
#     filtered_results = force_year_filter(faiss_results, time_filter)
#     print("[DEBUG] FAISS sau nƒÉm:", len(filtered_results))
#
#     if not filtered_results:
#         print("[‚ö†Ô∏è] FAISS l·ªçc r·ªóng sau khi √°p d·ª•ng th·ªùi gian, fallback all FAISS")
#         filtered_results = faiss_results
#
#     if not filtered_results:
#         return f"‚ùå Kh√¥ng t√¨m th·∫•y n·ªôi dung ph√π h·ª£p v·ªõi truy v·∫•n '{doc_name}'!"
#
#     context = "\n\n".join([res["content"] for res in filtered_results])[:3000]
#
#     response = openai.chat.completions.create(
#         model="gpt-4o",
#         messages=[
#             {"role": "system", "content": SYSTEM_PROMPT.strip()},
#             {"role": "user", "content": f"""üìñ **D·ªØ li·ªáu FAISS:**\n\n{context}\n\nüìå **Y√™u c·∫ßu:**\n{user_prompt}"""}
#         ],
#         max_tokens=3000,
#     )
#
#     return response.choices[0].message.content





